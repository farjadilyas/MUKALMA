{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fa44f7-42f3-4d21-8c4a-c9c6f3bea737",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "Creating a system which, given turns of conversation that has happened and a new turn, can return the most important topic(s) the conversation is revolving around\n",
    "\n",
    "Note: This will be fed into the knowledge retreival phases to provide the core context in addition to the latest turn of conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6b886-f020-4379-9761-b31b571ea66a",
   "metadata": {},
   "source": [
    "## Sample Data Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f089c55b-135d-47b6-8c56-bde32b77c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\"Hey! How are you doing?\", \"This COVID thing has been crazy hasn't it\", \"I heard the vaccines aren't all that effective\",\n",
    "       \"I heard Pfizer had something to do with the vaccines\", \"and what about Moderna? I'm pretty sure they were involved too\",\n",
    "       \"I'm not sure social distancing is useful in stopping the spread\"]\n",
    "docs.extend(docs)\n",
    "docs.extend(docs)\n",
    "docs.extend(docs)\n",
    "\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "# docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3f5fdb-9bfe-452c-9e9e-eeb6f5b6b7c6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03087343-b1e1-4cb0-944c-2a905bd1500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farja\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a196516-dde4-4ebd-a45a-fbad4810548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True, embedding_model=\"../../models/bert-base-cased-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ac8bb2-3f7e-4416-bd6b-2ee555466793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No sentence-transformers model found with name ../../models/bert-base-cased-squad2. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at ../../models/bert-base-cased-squad2 were not used when initializing BertModel: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████| 589/589 [13:40<00:00,  1.39s/it]\n",
      "2022-03-28 21:28:18,366 - BERTopic - Transformed documents to Embeddings\n",
      "2022-03-28 21:29:24,013 - BERTopic - Reduced dimensionality with UMAP\n",
      "2022-03-28 21:29:46,150 - BERTopic - Clustered UMAP embeddings with HDBSCAN\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4db1fc-c098-41c8-88ad-6893267123be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>10947</td>\n",
       "      <td>-1_the_to_of_and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>0_he_game_team_year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>709</td>\n",
       "      <td>1_edu_the_it_of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>561</td>\n",
       "      <td>2_that_of_god_is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>515</td>\n",
       "      <td>3____</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                 Name\n",
       "0     -1  10947     -1_the_to_of_and\n",
       "1      0    875  0_he_game_team_year\n",
       "2      1    709      1_edu_the_it_of\n",
       "3      2    561     2_that_of_god_is\n",
       "4      3    515                3____"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = topic_model.get_topic_info(); freq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebce4650-9af5-4116-97ae-a30e9068b9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 0.017976277241705883),\n",
       " ('game', 0.016807014189312745),\n",
       " ('team', 0.01569459667494884),\n",
       " ('year', 0.01127740493065954),\n",
       " ('the', 0.010826522447135929),\n",
       " ('games', 0.010601793995639252),\n",
       " ('was', 0.010445442727259373),\n",
       " ('his', 0.010272403028888195),\n",
       " ('in', 0.00958907970771917),\n",
       " ('they', 0.00894425107608824)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(0)  # Select the most frequent topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed0a241-f855-4865-8dc1-c892ac4f766e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6766800b-1409-4696-8cc5-54940753ba29",
   "metadata": {},
   "source": [
    "## Using genism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fc3c4f-ba35-46ac-bc9f-181975f1e121",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bfa9e2-1c58-46bc-b29b-98c3ce9eee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b4691-35dd-4519-b118-0e7d94763310",
   "metadata": {},
   "source": [
    "### Pre-process text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fcc9bb-c71a-4dde-a353-75f6c03fccae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread'], ['hey', 'doing'], ['covid', 'thing', 'crazy'], ['heard', 'vaccine', 'effective'], ['heard', 'pfizer', 'something', 'vaccine'], ['moderna', 'im', 'pretty', 'sure', 'involved'], ['im', 'sure', 'social', 'distancing', 'useful', 'stopping', 'spread']]\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemmatizer.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "clean_corpus = [clean(doc).split() for doc in docs]\n",
    "print(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101ada6b-fc61-41ff-aa3d-8f3f3270cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(text_data)corpus = [dictionary.doc2bow(text) for text in ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831cfa3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c89eee7a",
   "metadata": {},
   "source": [
    "## Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18d5fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farja\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc1a7799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('../../models/all-MiniLM-L6-v2', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3748847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sentence_similarity(msg, candidates):\n",
    "    msg_embedding = model.encode([msg])\n",
    "    candidate_embeddings = model.encode(candidates)\n",
    "    distances = cosine_similarity(msg_embedding, candidate_embeddings).flatten()\n",
    "    return distances\n",
    "\n",
    "def has_topic_changed(msg, prev_msg, control_msg, error_threshold=0.02):\n",
    "    distances = calc_sentence_similarity(msg, [prev_msg, control_msg])\n",
    "    print(f\"topic_change_dist: {distances}\")\n",
    "    return distances[1] - distances[0] > -error_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49e6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(message):\n",
    "    tokenized = sent_tokenize(message)\n",
    "    nouns = []\n",
    "    for sentence in tokenized:\n",
    "        wordsList = word_tokenize(sentence)\n",
    "        #print(wordsList)\n",
    "        # wordsList = [w for w in wordsList if not w in stop_words]\n",
    "        tagged = nltk.pos_tag(wordsList)\n",
    "        nouns.extend([tag[0] for tag in tagged if tag[1][:2] in ['NN', 'CD'] and tag[0].lower() not in ['hi', 'hey']])\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46392b6f",
   "metadata": {},
   "source": [
    "### Experimenting with knowledge transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "931c1806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['match', 'yesterday']\n"
     ]
    }
   ],
   "source": [
    "prev_m_k = []\n",
    "m_k = []\n",
    "cur_k = []\n",
    "topic_k = []\n",
    "while True:\n",
    "    m = input('User: ')\n",
    "    if m == 'exit':\n",
    "        break\n",
    "    m_k = tag_sentence(m)\n",
    "    prev_m_k = m_k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6784cf",
   "metadata": {},
   "source": [
    "### Clustering cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f2c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.cluster.vq import kmeans\n",
    "\n",
    "def list_sorted_args(l, reverse=False):\n",
    "    return sorted(range(len(l)), key=l.__getitem__, reverse=reverse)\n",
    "\n",
    "def find_highest_similarity_scores(scores, n=3):\n",
    "    s_idxs = list_sorted_args(scores)\n",
    "    s = [scores[i] for i in s_idxs]\n",
    "    s_len = len(s)\n",
    "    s_range = range(s_len)\n",
    "    \n",
    "    kclust = kmeans(np.matrix([s_range, s]).transpose(), n)\n",
    "    assigned_clusters = [abs(kclust[0][:, 0] - e).argmin() for e in s_range]\n",
    "    print(assigned_clusters)\n",
    "    \n",
    "    highest_cluster = assigned_clusters[-1]\n",
    "    highest_idxs = []\n",
    "    for i in range(s_len-1, -1, -1):\n",
    "        if assigned_clusters[i] != highest_cluster:\n",
    "            return highest_idxs\n",
    "        highest_idxs.append(s_idxs[i])\n",
    "    return highest_idxs\n",
    "\n",
    "#t = [0.12140948, 0.426371, 0.11862079, 0.44534147, 0.17006755, 0.55, 0.00, 0.00, 0.00, 0.00]\n",
    "t = [0, 0.2, 0.5, 1]\n",
    "[t[i] for i in find_highest_similarity_scores(t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d3fb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: I love football\n",
      "topic_change_dist: [0.14568186 0.14568186]\n",
      "topic has changed to ['football']\n",
      "time elapsed: 0.33107709884643555\n",
      "\n",
      "User: My favorite team is Brazil\n",
      "topic_change_dist: [0.52336955 0.07332079]\n",
      "topic has not changed, keywords: ['Brazil', 'team', 'football']\n",
      "time elapsed: 0.03590273857116699\n",
      "\n",
      "User: They won the world cup in 1970\n",
      "topic_change_dist: [0.40615582 0.01180051]\n",
      "scores: [0.36334264 0.11462341 0.19479725 0.18227434 0.21584925 0.54440093]\n",
      "s_idxs: [5, 0, 4, 2, 3, 1]\n",
      "topic has not changed, keywords: ['1970', 'Brazil', 'football', 'team', 'cup', 'world']\n",
      "time elapsed: 0.0718085765838623\n",
      "\n",
      "User: their best player is neymar\n",
      "topic_change_dist: [0.3478805  0.05280136]\n",
      "scores: [0.19667219 0.11755693 0.24733979 0.29790506 0.04338944]\n",
      "s_idxs: [3, 2, 0, 1, 4]\n",
      "topic has not changed, keywords: ['player', 'football', 'cup', 'world', '1970']\n",
      "time elapsed: 0.35477280616760254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m cur_topic_desc_keywords \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1076\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m     )\n\u001b[1;32m-> 1076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1121\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "topics = []\n",
    "keywords = []\n",
    "c_keywords = []\n",
    "t_keywords = []\n",
    "prev_msg = control_msg = \"Hey! How are you doing?\"\n",
    "prev_keywords = []\n",
    "\n",
    "# Keeps track of whether the topic changed in the previous turn\n",
    "topic_changed = False\n",
    "cur_topic_desc_keywords = []\n",
    "while True:\n",
    "    msg = input('\\nUser: ')\n",
    "    t1 = time.time()\n",
    "    if msg == 'exit':\n",
    "        break\n",
    "    c_keywords = tag_sentence(msg)\n",
    "    \n",
    "    if has_topic_changed(msg, prev_msg, control_msg):\n",
    "        keywords = c_keywords\n",
    "        print(f\"topic has changed to {keywords}\")\n",
    "        topic_changed = True\n",
    "    else:\n",
    "        if topic_changed:\n",
    "            topic_changed = False\n",
    "\n",
    "            # Compare the current sentence against the keywords in the previous turn and keep the most relevant ones\n",
    "            # until the topic changes\n",
    "            if len(keywords) > 3:\n",
    "                scores = calc_sentence_similarity(msg, keywords)\n",
    "                cur_topic_desc_keywords = [keywords[i] for i in find_highest_similarity_scores(scores)]\n",
    "            else:\n",
    "                cur_topic_desc_keywords = keywords\n",
    "                keywords = []\n",
    "            t_keywords = list(set(c_keywords) | set(cur_topic_desc_keywords) | set(keywords))\n",
    "        else:\n",
    "            # It's been >2 turns since the topic changed\n",
    "            t_keywords = list(set(c_keywords) | set(cur_topic_desc_keywords) | set(keywords))\n",
    "            if len(t_keywords) > 0:\n",
    "                s_scores = calc_sentence_similarity(msg, t_keywords)\n",
    "                print(f\"scores: {s_scores}\")\n",
    "                s_idxs = list_sorted_args(s_scores, reverse=True)\n",
    "                print(f\"s_idxs: {s_idxs}\")\n",
    "                t_keywords = [t_keywords[i] for i in s_idxs]\n",
    "        \n",
    "        if keywords is None:\n",
    "            keywords = []\n",
    "        print(f\"topic has not changed, keywords: {t_keywords}\")\n",
    "        keywords = c_keywords\n",
    "            \n",
    "    print(f\"time elapsed: {time.time() - t1}\")\n",
    "    prev_msg = msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d926fc",
   "metadata": {},
   "source": [
    "### backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4705c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi there! What's up?\n",
      "topic has not changed, keywords: []\n",
      "time elapsed: 0.3567070960998535\n",
      "User: Nothing much, what about you?\n",
      "topic has not changed, keywords: ['Nothing']\n",
      "time elapsed: 0.03793525695800781\n",
      "User: Let's just say it's a great day to play football\n",
      "topic has changed to ['day', 'football']\n",
      "time elapsed: 0.041112422943115234\n",
      "User: Did you watch the match yesterday?\n",
      "topic has not changed, keywords: ['Did', 'match', 'yesterday', 'day', 'football']\n",
      "time elapsed: 0.4401993751525879\n",
      "User: I did! What a game, Barcelona is back!\n",
      "topic has not changed, keywords: ['game', 'Barcelona', 'day', 'football', 'Did', 'match', 'yesterday']\n",
      "time elapsed: 0.33307862281799316\n",
      "User: Still not a match for Madrid though\n",
      "topic has not changed, keywords: ['match', 'Madrid', 'day', 'football', 'game', 'Barcelona']\n",
      "time elapsed: 0.3435804843902588\n",
      "User: Cricket is going great too, I went to watch one of the Australia vs Pakistan matches here in Rawalpindi\n",
      "topic has changed to ['Cricket', 'one', 'Australia', 'vs', 'Pakistan', 'matches', 'Rawalpindi']\n",
      "time elapsed: 0.3382277488708496\n",
      "User: Oh wow, bet Rawalpindi was packed!\n",
      "[2, 2, 2, 1, 1, 0, 0]\n",
      "topic has not changed, keywords: ['wow', 'Rawalpindi', 'Rawalpindi', 'matches', 'Cricket', 'one', 'Australia', 'vs', 'Pakistan', 'matches', 'Rawalpindi']\n",
      "time elapsed: 0.4771289825439453\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m cur_topic_desc_keywords \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1076\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m     )\n\u001b[1;32m-> 1076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1121\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "topics = []\n",
    "keywords = []\n",
    "c_keywords = []\n",
    "prev_msg = control_msg = \"Hey! How are you doing?\"\n",
    "prev_keywords = []\n",
    "\n",
    "# Keeps track of whether the topic changed in the previous turn\n",
    "topic_changed = False\n",
    "cur_topic_desc_keywords = []\n",
    "while True:\n",
    "    msg = input('User: ')\n",
    "    t1 = time.time()\n",
    "    if msg == 'exit':\n",
    "        break\n",
    "    c_keywords = tag_sentence(msg)\n",
    "    \n",
    "    if has_topic_changed(msg, prev_msg, control_msg):\n",
    "        keywords = c_keywords\n",
    "        print(f\"topic has changed to {keywords}\")\n",
    "        topic_changed = True\n",
    "    else:\n",
    "        if topic_changed:\n",
    "            topic_changed = False\n",
    "\n",
    "            # Compare the current sentence against the keywords in the previous turn and keep the most relevant ones\n",
    "            # until the topic changes\n",
    "            if len(keywords) > 3:\n",
    "                scores = calc_sentence_similarity(msg, keywords)\n",
    "                cur_topic_desc_keywords = [keywords[i] for i in find_highest_similarity_scores(scores)]\n",
    "            else:\n",
    "                cur_topic_desc_keywords = keywords\n",
    "                keywords = None\n",
    "        #print(\"um\", keywords)\n",
    "        if keywords is None:\n",
    "            keywords = []\n",
    "        print(f\"topic has not changed, keywords: {c_keywords + cur_topic_desc_keywords + keywords}\")\n",
    "        keywords = c_keywords\n",
    "            \n",
    "    print(f\"time elapsed: {time.time() - t1}\")\n",
    "    prev_msg = msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2d4f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
