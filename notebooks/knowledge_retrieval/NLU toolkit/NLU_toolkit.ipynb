{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to develop NER, POS, and SVAO Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\farja\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from spacy import displacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\farja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\farja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NER and POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 NER using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"I don't know much about COVID and the vaccines for it\"\n",
    "result = NER(raw_text.title())\n",
    "for word in result.ents:\n",
    "    print(word.text, word.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I Don'T Know Much About Covid And The Vaccines For It</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(result,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 POS Tagging using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_sentence(sentence):\n",
    "    wordsList = word_tokenize(sentence)\n",
    "    # wordsList = [w for w in wordsList if not w in stop_words]\n",
    "    tagged = nltk.pos_tag(wordsList)\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Who beat New Zealand in the 1992 World Cup Final?\n",
      "Model:  [('Who', 'WP'), ('beat', 'VBD'), ('New', 'NNP'), ('Zealand', 'NNP'), ('in', 'IN'), ('the', 'DT'), ('1992', 'CD'), ('World', 'NNP'), ('Cup', 'NNP'), ('Final', 'NNP'), ('?', '.')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m     raw_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     tokenized \u001b[38;5;241m=\u001b[39m sent_tokenize(raw_text)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tokenized:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1076\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1073\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1074\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1075\u001b[0m     )\n\u001b[1;32m-> 1076\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\ipykernel\\kernelbase.py:1121\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "    raw_text = input(\"User: \")\n",
    "    tokenized = sent_tokenize(raw_text)\n",
    "    \n",
    "    for sentence in tokenized:\n",
    "        tagged = tag_sentence(sentence)\n",
    "        \n",
    "        print(\"Model: \", tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Building a combined Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cinematography', 'science', 'art', 'motion-picture', 'photography', 'light', 'radiation', 'image', 'sensor', 'material', 'film', 'stock', 'lens', 'light', 'surface', 'camera', 'exposure', 'image', 'sensor', 'charge', 'pixel', 'video', 'file', 'display', 'processing']\n"
     ]
    }
   ],
   "source": [
    "raw_text = '''Cinematography is the science or art of motion-picture photography by recording light or other electromagnetic radiation, either electronically by means of an image sensor, or chemically by means of a light-sensitive material such as film stock.\n",
    "Typically, a lens is used to repeatedly focus the light reflected from objects into real images on the light-sensitive surface inside a camera during a questioned exposure, creating multiple images.\n",
    "With an electronic image sensor, this produces an electrical charge at each pixel, which is electronically processed and stored in a video file for subsequent display or processing.'''\n",
    "\n",
    "entities = []\n",
    "\n",
    "ner_result = NER(raw_text.title())\n",
    "\n",
    "sentences = sent_tokenize(raw_text)\n",
    "for sentence in sentences:\n",
    "    pos_tagged = tag_sentence(sentence)\n",
    "    for tags in pos_tagged:\n",
    "        if tags[1] in [\"NNP\", \"NN\"]:\n",
    "            entities.append(tags[0].lower())\n",
    "        # End if\n",
    "    # End for\n",
    "# End for\n",
    "print (entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Subject Verb Object Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''Cinematography is the science or art of motion-picture photography by recording light or other electromagnetic radiation, either electronically by means of an image sensor, or chemically by means of a light-sensitive material such as film stock.\n",
    "Typically, a lens is used to repeatedly focus the light reflected from objects into real images on the light-sensitive surface inside a camera during a questioned exposure, creating multiple images.\n",
    "With an electronic image sensor, this produces an electrical charge at each pixel, which is electronically processed and stored in a video file for subsequent display or processing.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 My Custom Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('light', 'record', 'the science')\n",
      "('other electromagnetic radiation', 'record', 'the science')\n",
      "('the light', 'focus', 'a lens')\n",
      "('objects into real images on inside a camera', 'reflect', 'the light')\n",
      "('a questioned exposure', 'reflect', 'the light')\n",
      "('an electrical charge at each pixel ,', 'produce', 'this')\n",
      "('which', 'process', 'a video file for subsequent display')\n",
      "('which', 'store', 'a video file for subsequent display')\n",
      "('a video file for', 'store', 'each pixel ,')\n",
      "--------------------------------------------------------\n",
      "('cinematography', 'is', 'science')\n",
      "('cinematography', 'is', 'means')\n",
      "('cinematography', 'is', 'art')\n",
      "('science', 'recording', 'light')\n",
      "('science', 'recording', 'other electromagnetic radiation')\n",
      "('means', 'material', 'stock')\n",
      "('lens', 'focus', 'repeatedly focus creating')\n",
      "('lens', 'focus', 'light')\n",
      "('light', 'reflected', 'objects')\n",
      "('light', 'reflected', 'questioned exposure')\n",
      "('light', 'objects', 'real images')\n",
      "('objects', 'images', 'light sensitive surface')\n",
      "('objects', 'images', 'camera')\n",
      "('this', 'produces', 'electrical charge')\n",
      "('pixel', 'stored', 'file')\n",
      "('pixel', 'file', 'subsequent display')\n",
      "('pixel', 'file', 'processing')\n"
     ]
    }
   ],
   "source": [
    "from subjectVerbObject import findSubjectVerbObjects, findSubjectVerbAdjectiveObjects, nlp\n",
    "tokens = nlp(raw_text)\n",
    "svos = findSubjectVerbObjects(tokens)\n",
    "for svo in svos:\n",
    "    print (svo)\n",
    "print (\"--------------------------------------------------------\")\n",
    "svaos = findSubjectVerbAdjectiveObjects(tokens)\n",
    "for svao in svaos:\n",
    "    print (svao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Using an existing codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Solution with more SVOs identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'subject_verb_object_extract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23817/1102903948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msubject_verb_object_extract\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindSVOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindSVOs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msvo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msvos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msvo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'subject_verb_object_extract'"
     ]
    }
   ],
   "source": [
    "from subject_verb_object_extract import findSVOs, nlp\n",
    "tokens = nlp(raw_text)\n",
    "svos = findSVOs(tokens)\n",
    "for svo in svos:\n",
    "    print (svo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Solution with \"IS\" SVOs identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'subject_object_extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23817/964709990.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msubject_object_extraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindSVAOs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfindSVOs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_sm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'textcat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msvaos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindSVAOs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'subject_object_extraction'"
     ]
    }
   ],
   "source": [
    "from subject_object_extraction import findSVAOs, findSVOs\n",
    "import en_core_web_sm\n",
    "parser = en_core_web_sm.load(disable=['ner','textcat'])\n",
    "parse = parser(raw_text)\n",
    "svaos = findSVAOs(parse)\n",
    "for svao in svaos:\n",
    "    print (svao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Testing Interface Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subjectVerbObject import extractSimilarSVAOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''Cinematography is the science or art of motion-picture photography by recording light or other electromagnetic radiation, either electronically by means of an image sensor, or chemically by means of a light-sensitive material such as film stock.\n",
    "Typically, a lens is used to repeatedly focus the light reflected from objects into real images on the light-sensitive surface inside a camera during a questioned exposure, creating multiple images.\n",
    "With an electronic image sensor, this produces an electrical charge at each pixel, which is electronically processed and stored in a video file for subsequent display or processing.'''\n",
    "\n",
    "user_text_1_1 = '''Hi buddy, What do you think about cinematography'''\n",
    "\n",
    "\n",
    "raw_text_2 = '''Blue is one of the three primary colours of pigments in painting and traditional colour theory, as well as in the RGB colour model.\n",
    "It lies between violet and green on the spectrum of visible light.\n",
    "The eye perceives blue when observing light with a dominant wavelength between approximately 450 and 495 nanometres.\n",
    "Most blues contain a slight mixture of other colors; azure contains some green, while ultramarine contains some violet.\n",
    "The clear daytime sky and the deep sea appear blue because of an optical effect known as Rayleigh scattering.\n",
    "An optical effect called Tyndall scattering explains blue eyes.\n",
    "Distant objects appear more blue because of another optical effect called atmospheric perspective.'''\n",
    "user_text_2_1 = '''Blue is my favorite primary color.'''\n",
    "\n",
    "raw_text_3 = '''The Royal Blue was the Baltimore and Ohio Railroad (B&O)'s flagship passenger train between New York City and Washington, D.C., in the United States, beginning in 1890.'''\n",
    "user_text_3_1 = '''Blue is always nice. I like royal blue.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The eye', 'perceives', 'blue')\n",
      "('Most blues', 'contain', 'a slight mixture of other colors')\n",
      "('The clear daytime sky', 'appear', 'blue')\n",
      "('the deep sea', 'appear', 'blue')\n",
      "('An optical effect', 'explains', 'blue eyes')\n",
      "('Distant objects', 'appear', 'more blue')\n",
      "('blue', 'is', 'one')\n",
      "('eye', 'perceives', 'blue')\n",
      "('blues', 'contain', 'slight mixture')\n",
      "('daytime sky', 'appear', 'blue')\n",
      "('sea', 'appear', 'blue')\n",
      "('effect', 'explains', 'blue eyes')\n",
      "('objects', 'appear', 'more blue')\n"
     ]
    }
   ],
   "source": [
    "similar_svaos = extractSimilarSVAOs(user_text_2_1, raw_text_2)\n",
    "for svaos in similar_svaos:\n",
    "    print (svaos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intent Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Training a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package nps_chat to\n",
      "[nltk_data]     C:\\Users\\farja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package nps_chat is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Downloading Chat model\n",
    "nltk.download('nps_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "posts = nltk.corpus.nps_chat.xml_posts()\n",
    "posts_text = [post.text for post in posts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the Train and Test Set in 80:20\n",
    "train_text = posts_text[:int(len(posts_text)*0.8)]\n",
    "test_text = posts_text[int(len(posts_text)*0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TFIDF features\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), min_df=0.001, max_df=0.7, analyzer='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(train_text)\n",
    "X_test = vectorizer.transform(test_text)\n",
    "y = [post.get('class') for post in posts]\n",
    "\n",
    "y_train = y[:int(len(posts_text) * 0.8)]\n",
    "y_test = y[int(len(posts_text) * 0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=700, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Gradient Boosting classifier to the Training set\n",
    "gb = GradientBoostingClassifier(n_estimators = 700, random_state=0)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model to the file\n",
    "import pickle\n",
    "pickle.dump(gb, open('intent.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Making New Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (gb.predict(vectorizer.transform([\"I love cinematography\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Code for intent module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "# Downloading NLTK Corpus\n",
    "nltk.download('nps_chat')\n",
    "\n",
    "# Setting up Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3), min_df=0.001, max_df=0.7, analyzer='word')\n",
    "posts = nltk.corpus.nps_chat.xml_posts()\n",
    "posts_text = [post.text for post in posts]\n",
    "train_text = posts_text[:int(len(posts_text)*0.8)]\n",
    "vectorizer.fit_transform(train_text)\n",
    "\n",
    "# Setting up Model\n",
    "intentRecognizer = pickle.load(open('intent.sav', 'rb'))\n",
    "\n",
    "# Testing\n",
    "text = \"I love cinematography\"\n",
    "pred = intentRecognizer.predict(vectorizer.transform([text]))\n",
    "print (pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
